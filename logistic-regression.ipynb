{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Alexis Jordan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets as ds\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "%matplotlib inline\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy is library for scientific computing in Python. It has efficient implementation of n-dimensional array (tensor) manupulations, which is useful for machine learning applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert a list into numpy array (tensor)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 4],\n",
       "       [2, 6, 9]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = [[1, 2, 4], [2, 6, 9]]\n",
    "a = np.array(b)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the dimensions of the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply simple arithmetic operation on all element of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  6, 12],\n",
       "       [ 6, 18, 27]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can transpose a tensor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [2, 6],\n",
       "       [4, 9]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(a.T.shape)\n",
    "a.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can apply aggregate functions on the whole tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or on one dimension of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  8, 13])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(a, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 17])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(a, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do element-wise arithmetic operation on two tensors (of the same size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  6, 20],\n",
       "       [ 2, 12,  9]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1 = np.array([[1, 2, 4], [2, 6, 9]])\n",
    "c2 = np.array([[2, 3, 5], [1, 2, 1]])\n",
    "c1 * c2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to multiply all columns of a tensor by vector (for example if you want to multiply all data features by their lables) you need a trick. This multiplication shows up in calculating the gradients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 4]\n",
      " [2 6 9]]\n",
      "[ 1 -1]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 2, 4], [2, 6, 9]])\n",
    "b = np.array([1,-1])\n",
    "print(a)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we want to multiply the first row of a by 1 and the second row of a by -1. Simply multiplying a by b does not work because a and b do not have the same dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,3) (2,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9bc1a869709f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,3) (2,) "
     ]
    }
   ],
   "source": [
    "a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this multiplication we first have to assume b has one column and then repeat the column of b with the number of columns in a. We use tile function to do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  1],\n",
       "       [-1, -1, -1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_repeat = np.tile(b,  (a.shape[1],1)).T\n",
    "print(b_repeat.shape)\n",
    "b_repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can multiply each column of a by b:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  4],\n",
       "       [-2, -6, -9]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * b_repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create inital random vector using numpy (using N(0,1)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 0 # mean\n",
    "sigma = 1 # standard deviation\n",
    "r = np.random.normal(mu,sigma, 1000) # draws 1000 samples from a normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply functions on tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of Normal distribution\n",
    "def normal(x, mu, sigma):\n",
    "    return np.exp( -0.5 * ((x-mu)/sigma)**2)/np.sqrt(2.0*np.pi*sigma**2)\n",
    "\n",
    "#probability of samples on the Normal distribution\n",
    "probabilities = normal(r, mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy has useful APIs for analysis. Here we plot the histogram of samples and also plot the probabilies to see if the samples follow the normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fcf395140a0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts, bins = np.histogram(r,50,density=True)\n",
    "plt.hist(bins[:-1], bins, weights=counts)\n",
    "plt.scatter(r, probabilities, c='b', marker='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    f = open(filename, 'r')\n",
    "    p = re.compile(',')\n",
    "    xdata = []\n",
    "    ydata = []\n",
    "    header = f.readline().strip()\n",
    "    varnames = p.split(header)\n",
    "    namehash = {}\n",
    "    for l in f:\n",
    "        li = p.split(l.strip())\n",
    "        xdata.append([float(x) for x in li[:-1]])\n",
    "        ydata.append(float(li[-1]))\n",
    "    \n",
    "    return np.array(xdata), np.array(ydata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming our data is x is available in numpy we use numpy to implement logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xtrain_whole, ytrain_whole) = read_data('spambase-train.csv')\n",
    "(xtest, ytest) = read_data('spambase-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of xtrain: (3601, 54)\n",
      "The shape of ytrain: (3601,)\n",
      "The shape of xtest: (1000, 54)\n",
      "The shape of ytest: (1000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of xtrain:\", xtrain_whole.shape)\n",
    "print(\"The shape of ytrain:\", ytrain_whole.shape)\n",
    "print(\"The shape of xtest:\", xtest.shape)\n",
    "print(\"The shape of ytest:\", ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training make we normalize the input data (features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmean = np.mean(xtrain_whole, axis=0)\n",
    "xstd = np.std(xtrain_whole, axis=0)\n",
    "xtrain_normal_whole = (xtrain_whole-xmean) / xstd\n",
    "xtest_normal = (xtest-xmean) / xstd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create a validation set. We create an array of indecies and permute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "permute_indicies = np.random.permutation(np.arange(xtrain_whole.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep the first 2600 data points as the training data and rest as the validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_normal = xtrain_normal_whole[permute_indicies[:2600]]\n",
    "ytrain = ytrain_whole[permute_indicies[:2600]]\n",
    "xval_normal = xtrain_normal_whole[permute_indicies[2600:]]\n",
    "yval = ytrain_whole[permute_indicies[2600:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiallizing the weights and bias with random values from N(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.random.normal(0, 1, xtrain_normal.shape[1]);\n",
    "bias = np.random.normal(0,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sigmoid function\n",
    "\n",
    "def sigmoid(v):\n",
    "    return np.exp(-np.logaddexp(0, -v)) # Numerically stable implementation of sigmoid function \n",
    "    \n",
    "    #return 1.0 / (1+np.exp(-v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use dot-product from numpy to calculate the margin and pass it to the sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w: weight vector (numpy array of size n)\n",
    "#b: numpy array of size 1\n",
    "#returns p(y=1|x, w, b)\n",
    "\n",
    "def prob(x, w, b):\n",
    "    return sigmoid(np.dot(x,w) + b);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also calculate $l_2$ penalty using linalg library of numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.618771529293618"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Cross Entropy Loss} = -\\sum_{(y^i,\\mathbf{x}^i)\\in\\mathcal{D}} \n",
    " y^i \\log p(y=1|\\mathbf{x}^i;\\mathbf{w},b)  +  (1-y^i) \\log (1 - p(y=1|\\mathbf{x}^i;\\mathbf{w},b)+\\frac{\\lambda}{2} \\|\\mathbf{w}\\|^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w: weight vector (numpy array of size n)\n",
    "#y_prob: p(y|x, w, b)\n",
    "#y_true: class variable data\n",
    "#lambda_: l2 penalty coefficient\n",
    "#returns the cross entropy loss\n",
    "\n",
    "def loss(w, y_prob, y_true, lambda_):\n",
    "    \n",
    "    return (-1.0 * np.sum(y_true*np.log(y_prob) + (1-y_true)*np.log(1-y_prob))) + (lambda_/2)*np.linalg.norm(weights)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x: input variables (data of size m x n with m data point and n features)\n",
    "#w: weight vector (numpy array of size n)\n",
    "#y_prob: p(y|x, w, b)\n",
    "#y_true: class variable data\n",
    "#lambda_: l2 penalty coefficient\n",
    "#returns tuple of gradient w.r.t w and w.r.t to bias\n",
    "\n",
    "def grad_w_b(x, w, y_prob, y_true, lambda_):\n",
    "    grad_w = np.zeros(w.shape)\n",
    "    grad_b = 0.0\n",
    "    \n",
    "    # Loop here?\n",
    "    grad_w = np.dot(x.T, (y_prob - y_true)) + (lambda_/2)*np.linalg.norm(weights)\n",
    "    grad_b = np.sum(y_prob - y_true)\n",
    "    \n",
    "    return (grad_w,grad_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#lambda_ is the coeffienct of l2 norm penalty\n",
    "#learning_rate is learning rate of gradient descent algorithm\n",
    "#max_iter determines the maximum number of iterations if the gradients descent does not converge.\n",
    "#continue the training while gradient > 0.1 or the number steps is less max_iter\n",
    "\n",
    "#returns model as tuple of (weights,bias)\n",
    "\n",
    "def fit(x, y_true, learning_rate, lambda_, max_iter, verbose=0):\n",
    "    weights = np.random.normal(0, 1, x.shape[1]);\n",
    "    bias = np.random.normal(0,1,1)\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        y_prob = prob(x, weights, bias)\n",
    "        grad_w, grad_b = grad_w_b(x, weights, y_prob, y_true, lambda_)\n",
    "        \n",
    "        weights -= learning_rate * grad_w\n",
    "        bias -= learning_rate * grad_b\n",
    "        \n",
    "        if np.linalg.norm(weights) < 0.1:\n",
    "            break\n",
    "            \n",
    "    print(loss(weights,  y_prob, y_true, lambda_))\n",
    "    return (weights, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(x, y_true, model):\n",
    "    w, b = model\n",
    "    return np.sum((prob(x, w, b)>0.5).astype(np.float) == y_true)  / y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431.26785927614736\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "lambda_ = 1.0\n",
    "\n",
    "model = fit(xtrain_normal, ytrain, learning_rate, lambda_, 10000, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9357692307692308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-49-c2c25048c40d>:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return np.sum((prob(x, w, b)>0.5).astype(np.float) == y_true)  / y_true.shape[0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy: \", accuracy(xtrain_normal, ytrain, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-e13aa8848119>:9: RuntimeWarning: divide by zero encountered in log\n",
      "  return (-1.0 * np.sum(y_true*np.log(y_prob) + (1-y_true)*np.log(1-y_prob))) + (lambda_/2)*np.linalg.norm(weights)\n",
      "<ipython-input-28-e13aa8848119>:9: RuntimeWarning: invalid value encountered in multiply\n",
      "  return (-1.0 * np.sum(y_true*np.log(y_prob) + (1-y_true)*np.log(1-y_prob))) + (lambda_/2)*np.linalg.norm(weights)\n",
      "<ipython-input-49-c2c25048c40d>:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return np.sum((prob(x, w, b)>0.5).astype(np.float) == y_true)  / y_true.shape[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "0.01 5 0.8931068931068931\n",
      "nan\n",
      "0.01 2 0.8931068931068931\n",
      "nan\n",
      "0.01 1 0.903096903096903\n",
      "nan\n",
      "0.01 0.1 0.8891108891108891\n",
      "nan\n",
      "0.01 0.01 0.8871128871128872\n",
      "nan\n",
      "0.001 5 0.9070929070929071\n",
      "540.6173541255529\n",
      "0.001 2 0.9150849150849151\n",
      "431.267859284646\n",
      "0.001 1 0.9140859140859141\n",
      "421.98424062774427\n",
      "0.001 0.1 0.9170829170829171\n",
      "421.56823120725886\n",
      "0.001 0.01 0.9170829170829171\n",
      "693.1176783516418\n",
      "0.0001 5 0.9070929070929071\n",
      "458.0183398475154\n",
      "0.0001 2 0.916083916083916\n",
      "430.6679647526205\n",
      "0.0001 1 0.9150849150849151\n",
      "421.9447159857278\n",
      "0.0001 0.1 0.9180819180819181\n",
      "421.66218421813716\n",
      "0.0001 0.01 0.9180819180819181\n",
      "494.87985940648883\n",
      "1e-05 5 0.913086913086913\n",
      "435.5295428019845\n",
      "1e-05 2 0.916083916083916\n",
      "431.51995218171527\n",
      "1e-05 1 0.9150849150849151\n",
      "425.37649813254524\n",
      "1e-05 0.1 0.9210789210789211\n",
      "424.40133737596454\n",
      "1e-05 0.01 0.922077922077922\n"
     ]
    }
   ],
   "source": [
    "#grid search for finding the best hyperparams and model\n",
    "\n",
    "best_model = None\n",
    "best_val = -1\n",
    "for lr in [0.01, 0.001, 0.0001, 0.00001]:\n",
    "    for la in [5, 2, 1, 0.1, 0.01]:\n",
    "        model = fit(xtrain_normal, ytrain, lr, la, 10000)\n",
    "        val_acc = accuracy(xval_normal, yval, model)\n",
    "        print(lr, la, val_acc)\n",
    "        if val_acc > best_val:\n",
    "            best_val = val_acc\n",
    "            best_model = model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-49-c2c25048c40d>:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return np.sum((prob(x, w, b)>0.5).astype(np.float) == y_true)  / y_true.shape[0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy: \", accuracy(xtest_normal, ytest, best_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
